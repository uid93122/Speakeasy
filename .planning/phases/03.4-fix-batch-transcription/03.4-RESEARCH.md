# Phase 03.4: Fix Batch Transcription - Research

**Researched:** 2026-01-30
**Domain:** Backend Service & Error Handling
**Confidence:** HIGH

## Summary

The "Batch Transcription" feature fails because the `BatchService` attempts to call a method `transcribe_file` on the `TranscriberService` which does not exist. The `TranscriberService` currently only supports in-memory transcription via `transcribe(audio_data)`.

To fix this, we must extend `TranscriberService` to handle file inputs, ensuring proper audio loading and resampling (to 16kHz) before passing data to the model. The recommended approach utilizes `faster_whisper.audio.decode_audio` for robust audio processing if available, or `soundfile` as a fallback.

**Primary recommendation:** Implement `TranscriberService.transcribe_file` using `faster_whisper`'s audio utilities to handle file loading and resampling.

## Standard Stack

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| `faster_whisper` | >=1.0.0 | Audio decoding & ASR | Includes robust ffmpeg-based audio loading/resampling |
| `soundfile` | (via dependencies) | Audio I/O | Standard Python audio library, used elsewhere in project |
| `numpy` | >=1.24.0 | Array manipulation | Required for audio buffer handling |

## Architecture Patterns

### Recommended Implementation

The `TranscriberService` should expose a helper for file-based transcription that bridges the gap between file paths and the numpy-based `transcribe` method.

```python
# backend/speakeasy/core/transcriber.py

def transcribe_file(self, file_path: str, language: Optional[str] = None) -> TranscriptionResult:
    """
    Transcribe an audio file.
    
    Args:
        file_path: Path to the audio file
        language: Language code or 'auto'
    """
    if not self.is_model_loaded:
        raise RuntimeError("No model loaded")

    try:
        # Use faster_whisper's robust audio decoding (handles ffmpeg, resampling to 16k)
        from faster_whisper.audio import decode_audio
        audio_data = decode_audio(file_path, sampling_rate=self.SAMPLE_RATE)
        
        # Call the existing in-memory transcribe method
        return self.transcribe(
            audio_data=audio_data,
            sample_rate=self.SAMPLE_RATE,
            language=language
        )
    except Exception as e:
        logger.error(f"Error reading audio file {file_path}: {e}")
        raise
```

### UI Feedback Pattern
The frontend (`BatchTranscription.tsx`) already contains logic to display error messages. Ensure the `error` field in `BatchFile` is correctly populated and propagated via WebSocket.

- **Status Field:** `file.status` ('failed') triggers the red UI state.
- **Error Message:** `file.error` displays the specific exception message.

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Audio Loading | `open()` + manual parsing | `faster_whisper.audio.decode_audio` | Handles multiple formats, resampling, and normalization correctly |
| Resampling | Custom interpolation | `decode_audio` (ffmpeg) | Correctly handles aliasing and sample rate conversion |

## Common Pitfalls

### Pitfall 1: Sample Rate Mismatch
**What goes wrong:** Loading audio at its native rate (e.g., 44.1kHz) and passing it to a model expecting 16kHz.
**Why it happens:** `soundfile.read` returns native rate by default.
**How to avoid:** Explicitly resample to 16000Hz. `decode_audio` does this automatically with `sampling_rate=16000`.

### Pitfall 2: Large File Memory Usage
**What goes wrong:** Loading a 2-hour audio file entirely into RAM.
**Why it happens:** `decode_audio` loads the full stream.
**How to avoid:** The current `transcribe` method supports chunking (`_transcribe_chunked`), but `decode_audio` loads everything first.
**Mitigation:** For Phase 3.4, loading into RAM is acceptable as a fix. Future optimization could stream via ffmpeg, but `_transcribe_chunked` already mitigates OOM during *inference*.

## Code Examples

### Correct Audio Loading (Standard)
```python
from faster_whisper.audio import decode_audio

# Loads, converts to mono, resamples to 16000, validates input
audio = decode_audio("path/to/file.mp3", sampling_rate=16000)
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| `soundfile.read` | `faster_whisper.audio.decode_audio` | Phase 03.4 | Supports more formats (mp3/m4a via ffmpeg) vs just wav/flac |

## Open Questions

1.  **FFmpeg Availability**
    - `faster_whisper` relies on `ffmpeg` being in the PATH or installed.
    - **Verification:** Ensure the runtime environment (Electron bundled Python) includes ffmpeg or statically links it. If `decode_audio` fails, fall back to `soundfile` (which supports fewer formats but works standalone).

## Sources

### Primary (HIGH confidence)
- Codebase analysis: `backend/speakeasy/services/batch.py` calls `transcribe_file`.
- Codebase analysis: `backend/speakeasy/core/transcriber.py` lacks `transcribe_file`.
- Library docs: `faster-whisper` documentation for `decode_audio`.

### Secondary (MEDIUM confidence)
- Frontend analysis: `BatchTranscription.tsx` appears to handle error states correctly, needing only backend support.

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - `faster-whisper` is already a core dependency.
- Architecture: HIGH - The missing method is the clear root cause.
- Pitfalls: MEDIUM - FFmpeg dependency needs verification in the packaged build.

**Research date:** 2026-01-30
